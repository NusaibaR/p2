{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from scipy.stats import randint as randint\n",
    "from scipy.stats import uniform\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "categories = [\"neg\" , \"pos\"]\n",
    "\n",
    "#read train files\n",
    "docs_to_train = sklearn.datasets.load_files(\"C:/Users/nusai/Desktop/UNI/4th Year/Comp 551/P2/comp-551-imbd-sentiment-classification/train/train\", \n",
    "      description=None, categories=categories,\n",
    "      load_content=True, encoding='utf-8', shuffle=True, random_state=42)\n",
    "\n",
    "#divide train set to train_data & cv_data\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(docs_to_train.data,\n",
    "    docs_to_train.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading test folder in order\n",
    "def X_test():\n",
    "    testdocs=[]\n",
    "    i=0\n",
    "    while i<25000:\n",
    "      file1 = open(\"C:/Users/nusai/Desktop/UNI/4th Year/Comp 551/P2/comp-551-imbd-sentiment-classification/test/\"+str(i)+\".txt\",\"r+\",encoding=\"utf-8\")\n",
    "      l=file1.read()\n",
    "      testdocs.append(l)\n",
    "      i=i+1\n",
    "      file1.close()\n",
    "    return testdocs \n",
    "\n",
    "#creating a stopwords list \n",
    "def stopwords_list():\n",
    "    \n",
    "    words = [ ]\n",
    "    with open('eng_st.txt','r') as f:\n",
    "        for line in f:\n",
    "            for word in line.split(','):\n",
    "               words.append(word)\n",
    "       \n",
    "    return words\n",
    "\n",
    "list_st = stopwords_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a pipline model to extract features and preform features transformation\n",
    "# then we slect one model to fit and predict our test_data             \n",
    "chi_k = 5000\n",
    "pclf = Pipeline([ \n",
    "    \n",
    "    ('vect',CountVectorizer(ngram_range=(1,2),token_pattern=r'\\b\\w+\\b', min_df=1)), #strip_accents='unicode')),#,stop_words= list_st)),ascii\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    #('dim_red', SelectKBest(chi2, chi_k)),\n",
    "    #('scale', MaxAbsScaler()),\n",
    "    ('norm', Normalizer()),\n",
    "    #('SVD', TruncatedSVD(1000)),\n",
    "    ('clf', LinearSVC(penalty ='l2',dual= True, C=5)),\n",
    "    #('clf', KNeighborsClassifier(n_neighbors=25)),\n",
    "    #('clf', SVC( gamma='auto', kernel='linear', C=7)),\n",
    "    #('clf', LogisticRegression(C=5, class_weight='balanced')),#{\"neg\":1.2})),\n",
    "    #('clf', DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "\n",
    "pclf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pclf.predict(X_cv)\n",
    "\n",
    "#find f1 score of cv (fixed cv) \n",
    "print(metrics.classification_report(y_cv, y_pred, digits= 5,\n",
    "    target_names=docs_to_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper method to evalute a model\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using k-fold cross validation and report on the performance of the model variants\n",
    "def validation_pipeline():          \n",
    "    params = {\"vect__ngram_range\": [(1,2),(1,3)],  \n",
    "         \"tfidf__use_idf\": [True,False],\n",
    "         #SVC param\n",
    "         \"clf__C\": np.arange(4, 9, 0.5),\n",
    "         }\n",
    "    \n",
    "    seed = 551 # Very important for repeatibility in experiments!\n",
    "    \n",
    "    random_search = RandomizedSearchCV(pclf, param_distributions = params, cv=2, verbose = 10, random_state = seed, n_iter = 5)\n",
    "    random_search.fit(X_train, y_train)\n",
    "    \n",
    "    report(random_search.cv_results_)\n",
    "    y_pred = random_search.predict(X_cv)\n",
    "    \n",
    "    print(metrics.classification_report(y_cv, y_pred,digits= 5,\n",
    "        target_names=docs_to_train.target_names))\n",
    "       \n",
    "#validation_pipeline()   \n",
    " \n",
    "    \n",
    "#other method to calculate the score on k-fold cv \n",
    "# only one cv_scores() or validation_pipline should be called    \n",
    "def cv_scores():\n",
    "    \n",
    "   scores = cross_val_score(pclf, docs_to_train.data, docs_to_train.target, cv=3, verbose = 10, scoring='f1_macro')\n",
    "   print(scores)\n",
    "   print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))    \n",
    "\n",
    "\n",
    "#cv_scores()\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper method to create csv file    \n",
    "def create_csv(): \n",
    "    \n",
    "    testdocs = X_test()\n",
    "    y_pred_new = pclf.predict(testdocs)    \n",
    "    df = pd.DataFrame(columns=['Id' , 'Category'])\n",
    "    \n",
    "    for i in range(len(y_pred_new)): \n",
    "        #csv.write(i,y_pred_new[i])\n",
    "    \t#print(\"X=%s, Predicted=%s\" % (i, y_pred_new[i]))\n",
    "        list = [i,y_pred_new[i]]\n",
    "        df.loc[i]=list\n",
    "        \n",
    "    print(df)\n",
    "    df.to_csv('ML_p2.csv')\n",
    "    \n",
    "create_csv()  \n",
    "    \n",
    "    \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
